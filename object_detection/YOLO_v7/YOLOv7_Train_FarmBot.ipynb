{"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/stuser/Python_md/blob/master/object_detection/YOLO_v7/YOLOv7_Train_FarmBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{"id":"5FolrgfORAnO"},"id":"5FolrgfORAnO"},{"cell_type":"markdown","source":["## AIA&FBTUG – 資料標記與模型訓練(yolo)\n","- AIA&FBTUG專案說明簡報檔案連結:\n","https://drive.google.com/open?id=1WBD60MDXIpr1XpBloE1fy2RQ0k72qrr9inT-ggNkCMc\n","\n","- 學員成果簡報影片連結:\n","https://youtu.be/iY2RZGmV3sY\n","\n","- Yolo模型成果影片連結:\n","https://youtu.be/Bzf8ZjIEqGI\n","\n","- Yolo模型在realtime coco資料集的排名\n","https://paperswithcode.com/sota/real-time-object-detection-on-coco"],"metadata":{"id":"wr2WxUVEwdx0"},"id":"wr2WxUVEwdx0"},{"cell_type":"markdown","source":["# YOLOv7 模型架構\n","\n","<img src=\"https://github.com/stuser/Python_md/blob/master/object_detection/YOLO_v7/pic/yolov7_model.png?raw=true\"  width=\"640\" height=\"320\">\n"],"metadata":{"id":"Z5DZstI_z9bp"},"id":"Z5DZstI_z9bp"},{"cell_type":"markdown","source":["### 執行環境"],"metadata":{"id":"PUvxUyylExrz"},"id":"PUvxUyylExrz"},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfUlYAdhwlqz","executionInfo":{"status":"ok","timestamp":1683274313888,"user_tz":-480,"elapsed":14,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"a50f8856-e53a-47fb-960f-f6208fd9fda2"},"id":"PfUlYAdhwlqz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri May  5 08:11:53 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# verify CUDA\n","!/usr/local/cuda/bin/nvcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4ubtNRTugPW","executionInfo":{"status":"ok","timestamp":1683274318933,"user_tz":-480,"elapsed":290,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"81c5b497-2e36-460f-a3c8-78a17fcaa7e9"},"id":"w4ubtNRTugPW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}]},{"cell_type":"markdown","id":"419e9476","metadata":{"id":"419e9476"},"source":["### 下載課程所需檔案 (YOLOv7, Dataset)"]},{"cell_type":"markdown","source":["#### YOLOv7(Github程式檔)"],"metadata":{"id":"LAspwPUaFSuZ"},"id":"LAspwPUaFSuZ"},{"cell_type":"code","source":["!git clone https://github.com/WongKinYiu/yolov7.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbV05N-f785a","executionInfo":{"status":"ok","timestamp":1683877813785,"user_tz":-480,"elapsed":10526,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"e05bdc9c-0ec5-4efb-ce9f-4bfd844af2b8"},"id":"AbV05N-f785a","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1157, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 1157 (delta 10), reused 14 (delta 7), pack-reused 1139\u001b[K\n","Receiving objects: 100% (1157/1157), 70.42 MiB | 7.58 MiB/s, done.\n","Resolving deltas: 100% (498/498), done.\n"]}]},{"cell_type":"code","source":["%pip install -qr /content/yolov7/requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciLlxQZk8ES7","executionInfo":{"status":"ok","timestamp":1683877824529,"user_tz":-480,"elapsed":6498,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"4ca75cd8-6875-48e0-b5b2-006fb4693718"},"id":"ciLlxQZk8ES7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["%matplotlib inline\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import os\n","import glob\n","import random\n","import PIL\n","import sys\n","from IPython.display import Image\n","\n","#把 yolov7 這個資料夾設成 Python 是找得到的路徑\n","sys.path.insert(0,'./yolov7')"],"metadata":{"id":"rTW7mI8L8VMx"},"id":"rTW7mI8L8VMx","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### FarmBot-VD03(彩椒資料集)"],"metadata":{"id":"s3mSfd_cFVUR"},"id":"s3mSfd_cFVUR"},{"cell_type":"markdown","source":["FarmBot-彩椒照片資料集(665mb)連結: https://drive.google.com/file/d/1zrR3-6YBXCWVDp-GDx9D0vcMeIA2vM74/view?usp=share_link\n"],"metadata":{"id":"aj7x1d1IuOoN"},"id":"aj7x1d1IuOoN"},{"cell_type":"code","source":["!pip install -q gdown\n","\n","!gdown --id 1zrR3-6YBXCWVDp-GDx9D0vcMeIA2vM74"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Bjvm1KHuImG","executionInfo":{"status":"ok","timestamp":1683274357023,"user_tz":-480,"elapsed":16355,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"8f87199b-abba-4e82-83ee-1e1a85772f54"},"id":"5Bjvm1KHuImG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1zrR3-6YBXCWVDp-GDx9D0vcMeIA2vM74\n","To: /content/VD03.zip\n","100% 665M/665M [00:11<00:00, 58.2MB/s]\n"]}]},{"cell_type":"code","source":["!unzip VD03.zip > logs"],"metadata":{"id":"XcF8TdnlwQyM"},"id":"XcF8TdnlwQyM","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["手動整理一下資料匣:\n","把VD03資料匣移入yolov7資料匣內,方便模型訓練叫用。\n","\n","標記的類別:\n","- 0_pepper_flower\n","- 1_pepper_young\n","- 2_pepper_matured\n","- 3_pepper_covered"],"metadata":{"id":"JxQUiaEk142H"},"id":"JxQUiaEk142H"},{"cell_type":"code","source":["peper_label_list = ['0_pepper_flower','1_pepper_young','2_pepper_matured','3_pepper_covered']"],"metadata":{"id":"61T_MjCexWB-"},"id":"61T_MjCexWB-","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"P1yUcE9KLYOk"},"id":"P1yUcE9KLYOk"},{"cell_type":"markdown","id":"0b363a9b","metadata":{"id":"0b363a9b"},"source":["# YOLOv7 實作\n"]},{"cell_type":"markdown","id":"e68b2961","metadata":{"id":"e68b2961"},"source":["## 1. 確認資料集格式\n","   \n","![](https://albumentations.ai/docs/images/getting_started/augmenting_bboxes/bbox_formats.jpg)\n","\n","依照上圖yolo的BBox的座標表示計算為:\n","\n","[((420 + 98) / 2) / 640, ((462 + 345) / 2) / 480, 322 / 640, 117 / 480] (需依照片尺寸640*480正規化) \n","\n","得到: [0.4046875, 0.840625, 0.503125, 0.24375]\n","\n","(source: [albumentations.ai](https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/#yolo))"]},{"cell_type":"code","execution_count":null,"id":"acebedea","metadata":{"id":"acebedea"},"outputs":[],"source":["\n","name = 'VD03'  # 資料集名稱\n","classes = peper_label_list  # 修改自己的類別\n","\n","train_image_path = f'{name}/train/images/'\n","train_label_path = f'{name}/train/labels/'\n","valid_image_path = f'{name}/valid/images/'\n","valid_label_path = f'{name}/valid/labels/'\n","\n","if not os.path.exists(train_image_path):\n","    os.makedirs(train_image_path)\n","if not os.path.exists(train_label_path):\n","    os.makedirs(train_label_path)\n","if not os.path.exists(valid_image_path):\n","    os.makedirs(valid_image_path)\n","if not os.path.exists(valid_label_path):\n","    os.makedirs(valid_label_path)"]},{"cell_type":"markdown","id":"8cd2d1f3","metadata":{"id":"8cd2d1f3"},"source":["## 2. 更改設定檔案(yaml)\n","yolov7有三個基本的設定檔要設定:\n","- (1) 依照 cfg/training/yolov7.yaml 製作模型訓練設定 yaml檔 (有P5/P6/tiny的版本)\n","- (2) 依照 data/coco.yaml 製作一個資料集設定 yaml檔\n","- (3) 依照 data/hyp.scratch.p5.yaml 模型超參數設定 yaml檔 (有P5/P6/tiny的版本)"]},{"cell_type":"markdown","id":"3beea9c9","metadata":{"id":"3beea9c9"},"source":["將yolov7.yaml 設定檔複製一份\n"," \n","!cp 要複製的檔案 新檔案名稱"]},{"cell_type":"code","execution_count":null,"id":"1da4d0ea","metadata":{"id":"1da4d0ea"},"outputs":[],"source":["!cp yolov7/cfg/training/yolov7.yaml yolov7/cfg/training/yolov7-VD03.yaml"]},{"cell_type":"markdown","id":"eecaf7e9","metadata":{"id":"eecaf7e9"},"source":["將class的地方改成自己的class數量\n","- 你可以手動去修改yaml文件檔案\n","- 或是使用以下指令(sed)來修改yaml文件檔\n","\n","!sed -n -e (顯示) 第幾行 檔案名稱"]},{"cell_type":"code","execution_count":null,"id":"4d0c055f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4d0c055f","executionInfo":{"status":"ok","timestamp":1683274429618,"user_tz":-480,"elapsed":6,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"19660a2d-c0fe-4acc-89f4-067fb3085235"},"outputs":[{"output_type":"stream","name":"stdout","text":["nc: 80  # number of classes\n"]}],"source":["!sed -n -e 2p yolov7/cfg/training/yolov7-VD03.yaml"]},{"cell_type":"markdown","id":"22a4fc1a","metadata":{"id":"22a4fc1a"},"source":["#### (1) 依照 cfg/training/yolov7.yaml 製作\n","\n","!sed -i (修改) 第幾行/欲修改的字/目標字/ 檔案名稱"]},{"cell_type":"code","execution_count":null,"id":"034cd458","metadata":{"id":"034cd458"},"outputs":[],"source":["!sed -i '2s/80/4/' yolov7/cfg/training/yolov7-VD03.yaml"]},{"cell_type":"code","execution_count":null,"id":"dadf99a6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dadf99a6","executionInfo":{"status":"ok","timestamp":1683274434534,"user_tz":-480,"elapsed":5,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"47fabb04-9975-4e41-afbd-063274c00c80"},"outputs":[{"output_type":"stream","name":"stdout","text":["nc: 4  # number of classes\n"]}],"source":["!sed -n -e 2p yolov7/cfg/training/yolov7-VD03.yaml"]},{"cell_type":"markdown","id":"2e1a0f59","metadata":{"id":"2e1a0f59"},"source":["#### (2) 依照 data/coco.yaml 製作\n","參考data/coco.yaml 製作一個自己資料集的yaml"]},{"cell_type":"code","execution_count":null,"id":"61c7bdde","metadata":{"id":"61c7bdde"},"outputs":[],"source":["text = \\\n","    \"\"\"\n","    train: ./VD03/train # 訓練資料夾位置\n","    val: ./VD03/valid # 驗證資料夾位置\n","    test: ./VD03/valid # 測試資料夾位置\n","\n","    # number of classes\n","    nc: 4 # <-需修改成自己的類別數量\n","\n","    # class names\n","    names: ['0_pepper_flower','1_pepper_young','2_pepper_matured','3_pepper_covered']\n","    \"\"\""]},{"cell_type":"code","execution_count":null,"id":"532bbd90","metadata":{"id":"532bbd90"},"outputs":[],"source":["with open(f'yolov7/data/{name}.yaml', 'w') as file:\n","    file.write(text)"]},{"cell_type":"markdown","source":["#### (3) 依照 data/hyp.scratch.p5.yaml 製作\n","客製化訓練的超參數設定"],"metadata":{"id":"hjx2YVTVH6aZ"},"id":"hjx2YVTVH6aZ"},{"cell_type":"code","source":["!cp yolov7/data/hyp.scratch.custom.yaml yolov7/data/hyp.VD03.yaml"],"metadata":{"id":"bbJf36oaH6_I"},"id":"bbJf36oaH6_I","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"SqFTfRSbItuP"},"id":"SqFTfRSbItuP"},{"cell_type":"markdown","id":"d8782513","metadata":{"id":"d8782513"},"source":["## 模型訓練"]},{"cell_type":"markdown","id":"8f97dea5","metadata":{"id":"8f97dea5"},"source":["#### 下載預訓練權重檔案\n","\n","下載預訓練權重檔案\n","https://github.com/WongKinYiu/yolov7\n","\n","release v1.0 ([https://github.com/WongKinYiu/yolov7/releases/tag/v0.1](https://github.com/WongKinYiu/yolov7/releases/tag/v0.1))\n","\n","**Transfer learning**\n","\n","可供下載的預訓練權重檔名如下:\n","- yolov7.pt (註:預設是P5的模型架構)\n","- yolov7_training.pt (P5)\n","- yolov7x_training.pt (P5)\n","- yolov7-w6_training.pt (註:這是P6模型架構的版本)\n","- yolov7-e6_training.pt (P6)\n","- yolov7-d6_training.pt (P6)\n","- yolov7-e6e_training.pt (P6)\n","\n","請將權重檔案放置於yolov7/weights/資料夾底下"]},{"cell_type":"code","source":["!wget -P ./yolov7/weights https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8_NyYdp4xHe","executionInfo":{"status":"ok","timestamp":1683274452623,"user_tz":-480,"elapsed":1047,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"1934d71b-e68d-47db-ea7c-4bcabbcd93e7"},"id":"G8_NyYdp4xHe","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-05 08:14:11--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230505T081411Z&X-Amz-Expires=300&X-Amz-Signature=69d546ef347dfdfb1517c6a007f47258929c913d219887dbda33c76f12ffd270&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-05-05 08:14:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230505T081411Z&X-Amz-Expires=300&X-Amz-Signature=69d546ef347dfdfb1517c6a007f47258929c913d219887dbda33c76f12ffd270&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75628875 (72M) [application/octet-stream]\n","Saving to: ‘./yolov7/weights/yolov7_training.pt’\n","\n","yolov7_training.pt  100%[===================>]  72.12M   231MB/s    in 0.3s    \n","\n","2023-05-05 08:14:11 (231 MB/s) - ‘./yolov7/weights/yolov7_training.pt’ saved [75628875/75628875]\n","\n"]}]},{"cell_type":"markdown","id":"4854c4d3","metadata":{"id":"4854c4d3"},"source":["#### 模型訓練參數\n","執行訓練，訓練參數介紹：\n","- --weights : 預先訓練的權重路徑(weights/yolov7_training.pt)\n","- --cfg：模型設定檔案路徑(cfg/training/yolov7-VD03.yaml)\n","- --data：資料集設定檔案路徑(data/VD03.yaml)\n","- --device：GPU設定(單張GPU時,設為0)\n","- --batch-size：一次訓練照片張數\n","- --epoch： 訓練回合數\n","\n","其他可調控參數可置train.py中察看\n","\n","### Single GPU finetuning for custom dataset\n","\n","```\n","# finetune p5 models\n","python train.py --workers 8 --device 0 --batch-size 32 --data data/custom.yaml --img 640 640 --cfg cfg/training/yolov7-custom.yaml --weights 'yolov7_training.pt' --name yolov7-custom --hyp data/hyp.scratch.custom.yaml\n","\n","# finetune p6 models\n","python train_aux.py --workers 8 --device 0 --batch-size 16 --data data/custom.yaml --img 1280 1280 --cfg cfg/training/yolov7-w6-custom.yaml --weights 'yolov7-w6_training.pt' --name yolov7-w6-custom --hyp data/hyp.scratch.custom.yaml\n","```\n","\n"]},{"cell_type":"markdown","source":["**(重要)因為要在yolov7資料匣內執行train.py程式,故需確認以下事項：**\n","- 在Colab使用環境下，**使用%cd更改當前目錄位置到 yolov7資料匣**.\n","- **把VD03資料匣拉到yolov7資料匣裡面**."],"metadata":{"id":"M8e3Q5xWAok7"},"id":"M8e3Q5xWAok7"},{"cell_type":"code","source":["%cd yolov7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"plGTtKoEAi4F","executionInfo":{"status":"ok","timestamp":1683274464602,"user_tz":-480,"elapsed":249,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"32cbb0dc-d319-43dd-f7fa-d3643dcf1bff"},"id":"plGTtKoEAi4F","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n"]}]},{"cell_type":"markdown","source":["(**重要)如果你要使用P6模型架構做訓練，請修改(utils/loss.py)以下兩行程式碼**\n","\n","If you're training P6 models like e6 or w6 or x, then you'll need to change the following lines as well:\n","\n","(reference: https://github.com/WongKinYiu/yolov7/issues/1101)\n","\n","```\n","1389 - matching_matrix = torch.zeros_like(cost) to matching_matrix = torch.zeros_like(cost, device=\"cpu\")\n","\n","1543 - matching_matrix = torch.zeros_like(cost) to matching_matrix = torch.zeros_like(cost, device=\"cpu\")\n","\n","```\n","in the same file (utils/loss.py)."],"metadata":{"id":"L9OESojFIKNC"},"id":"L9OESojFIKNC"},{"cell_type":"markdown","source":["#### 進行模型訓練"],"metadata":{"id":"aGQDaTRhJcN1"},"id":"aGQDaTRhJcN1"},{"cell_type":"code","execution_count":null,"id":"bcb164a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcb164a1","executionInfo":{"status":"ok","timestamp":1683274907230,"user_tz":-480,"elapsed":426222,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"e3a4b6a3-5ae6-4acc-a762-63517d4f29ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-05 08:14:45.858520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-05 08:14:46.761641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16150.875MB)\n","\n","Namespace(weights='weights/yolov7_training.pt', cfg='cfg/training/yolov7-VD03.yaml', data='data/VD03.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=5, batch_size=8, img_size=[1024, 1024], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp', total_batch_size=8)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     50338  models.yolo.IDetect                     [4, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37212738 parameters, 37212738 gradients, 105.2 GFLOPS\n","\n","Transferred 555/566 items from weights/yolov7_training.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'VD03/train/labels' images and labels... 457 found, 2 missing, 0 empty, 0 corrupted: 100% 459/459 [00:00<00:00, 955.76it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: VD03/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'VD03/valid/labels' images and labels... 164 found, 2 missing, 0 empty, 0 corrupted: 100% 166/166 [00:00<00:00, 608.80it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: VD03/valid/labels.cache\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.43, Best Possible Recall (BPR) = 1.0000\n","Image sizes 1024 train, 1024 test\n","Using 4 dataloader workers\n","Logging results to runs/train/exp\n","Starting training for 5 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/4     3.18G   0.07189   0.03018   0.02514    0.1272        11      1024: 100% 58/58 [01:29<00:00,  1.54s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.60it/s]\n","                 all         166         606     0.00546      0.0183     0.00144    0.000272\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/4     14.8G   0.06149   0.02411   0.02245     0.108         7      1024: 100% 58/58 [01:02<00:00,  1.08s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.70it/s]\n","                 all         166         606      0.0907       0.142      0.0502      0.0114\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/4     14.8G   0.05501   0.02158   0.01937   0.09595        18      1024: 100% 58/58 [01:03<00:00,  1.09s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:05<00:00,  2.11it/s]\n","                 all         166         606       0.115       0.226      0.0981      0.0344\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/4     14.8G   0.04896   0.01843   0.01862   0.08601         7      1024: 100% 58/58 [01:01<00:00,  1.07s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:04<00:00,  2.34it/s]\n","                 all         166         606      0.0644       0.318       0.068      0.0214\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/4     14.8G   0.04616   0.01896   0.01789   0.08301        19      1024: 100% 58/58 [01:03<00:00,  1.10s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.67it/s]\n","                 all         166         606       0.445       0.403       0.205       0.099\n","     0_pepper_flower         166           8           1           0    2.89e-05    1.45e-05\n","      1_pepper_young         166         430       0.351       0.672       0.455        0.21\n","    2_pepper_matured         166          35       0.193         0.6       0.184       0.117\n","    3_pepper_covered         166         133       0.237       0.338       0.182      0.0699\n","5 epochs completed in 0.112 hours.\n","\n","Optimizer stripped from runs/train/exp/weights/last.pt, 74.9MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 74.9MB\n"]}],"source":["# finetune p5 models\n","!python train.py --weights weights/yolov7_training.pt --img 1024 1024 --cfg cfg/training/yolov7-VD03.yaml --data data/VD03.yaml --device 0 --batch-size 8 --epoch 10\n"]},{"cell_type":"markdown","source":["以下是給retrain方便呼叫使用"],"metadata":{"id":"hEzBH_0IJ_2w"},"id":"hEzBH_0IJ_2w"},{"cell_type":"code","source":["#!python train.py --weights runs/train/exp/weights/best.pt --img 1024 1024 --cfg cfg/training/yolov7-VD03.yaml --data data/VD03.yaml --device 0 --batch-size 8 --epoch 10"],"metadata":{"id":"RYhvnBNaNZZd","executionInfo":{"status":"ok","timestamp":1683275730974,"user_tz":-480,"elapsed":795857,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aac33359-1371-4e7d-d80e-c84743fa2a37"},"id":"RYhvnBNaNZZd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-05 08:22:17.352712: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-05 08:22:18.382128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16150.875MB)\n","\n","Namespace(weights='runs/train/exp/weights/best.pt', cfg='cfg/training/yolov7-VD03.yaml', data='data/VD03.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=10, batch_size=8, img_size=[1024, 1024], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp2', total_batch_size=8)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1     50338  models.yolo.IDetect                     [4, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37212738 parameters, 37212738 gradients, 105.2 GFLOPS\n","\n","Transferred 564/566 items from runs/train/exp/weights/best.pt\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'VD03/train/labels.cache' images and labels... 457 found, 2 missing, 0 empty, 0 corrupted: 100% 459/459 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'VD03/valid/labels.cache' images and labels... 164 found, 2 missing, 0 empty, 0 corrupted: 100% 166/166 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.43, Best Possible Recall (BPR) = 1.0000\n","Image sizes 1024 train, 1024 test\n","Using 4 dataloader workers\n","Logging results to runs/train/exp2\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/9     3.16G   0.04084    0.0179   0.01696    0.0757        11      1024: 100% 58/58 [01:30<00:00,  1.57s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.64it/s]\n","                 all         166         606       0.466       0.362       0.241       0.132\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/9     14.5G   0.04259   0.01771   0.01742   0.07771         7      1024: 100% 58/58 [01:05<00:00,  1.13s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.78it/s]\n","                 all         166         606       0.432       0.384       0.183      0.0815\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/9     14.5G   0.04413   0.01633   0.01594   0.07641        18      1024: 100% 58/58 [01:05<00:00,  1.13s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:05<00:00,  1.97it/s]\n","                 all         166         606       0.464       0.307       0.204      0.0882\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/9     14.5G   0.04365   0.01429   0.01607   0.07401         7      1024: 100% 58/58 [01:01<00:00,  1.06s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:05<00:00,  2.09it/s]\n","                 all         166         606       0.151       0.333       0.142      0.0429\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/9     14.5G   0.04786   0.01524   0.01553   0.07862        19      1024: 100% 58/58 [01:10<00:00,  1.22s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:05<00:00,  2.06it/s]\n","                 all         166         606       0.258       0.438        0.31       0.169\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       5/9     14.5G    0.0421   0.01625   0.01497   0.07331        25      1024: 100% 58/58 [01:03<00:00,  1.10s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:05<00:00,  1.87it/s]\n","                 all         166         606        0.37       0.451       0.335       0.187\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       6/9     14.5G   0.04047   0.01477   0.01337   0.06861        11      1024: 100% 58/58 [01:04<00:00,  1.11s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:04<00:00,  2.22it/s]\n","                 all         166         606       0.302       0.445       0.281      0.0927\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       7/9     14.5G   0.03862   0.01495   0.01252   0.06609        11      1024: 100% 58/58 [01:04<00:00,  1.12s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.74it/s]\n","                 all         166         606       0.388       0.448       0.367       0.202\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       8/9     14.5G   0.03658    0.0151   0.01219   0.06386        31      1024: 100% 58/58 [01:02<00:00,  1.08s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:05<00:00,  2.10it/s]\n","                 all         166         606         0.5       0.435       0.413       0.159\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       9/9     14.5G   0.03542   0.01401    0.0116   0.06102        33      1024: 100% 58/58 [01:03<00:00,  1.09s/it]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 11/11 [00:06<00:00,  1.72it/s]\n","                 all         166         606       0.468       0.487       0.449       0.288\n","     0_pepper_flower         166           8        0.37        0.25       0.237      0.0996\n","      1_pepper_young         166         430       0.644       0.726       0.731       0.474\n","    2_pepper_matured         166          35        0.35       0.371       0.269       0.226\n","    3_pepper_covered         166         133        0.51       0.603        0.56       0.354\n","10 epochs completed in 0.217 hours.\n","\n","Optimizer stripped from runs/train/exp2/weights/last.pt, 74.9MB\n","Optimizer stripped from runs/train/exp2/weights/best.pt, 74.9MB\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"57fsVFlsLcht"},"id":"57fsVFlsLcht"},{"cell_type":"markdown","source":["## 載入模型(權重)\n","將訓練好的模型權重，重新載入到yolov7的模型，我們要丟照片做結果呈現測試"],"metadata":{"id":"hTdCLZSqjskC"},"id":"hTdCLZSqjskC"},{"cell_type":"code","source":["#接下來使用hubconf套件中的custom,很容易就可以把我們的YOLOv7模型讀進Python中\n","from hubconf import custom\n","\n","model = custom(path_or_model='runs/train/exp2/weights/best.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5psIGPvjr86","executionInfo":{"status":"ok","timestamp":1683275789117,"user_tz":-480,"elapsed":6029,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"923b2f27-64b7-4cbd-ef54-1bd8f8c97fef"},"id":"n5psIGPvjr86","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["Adding autoShape... \n"]}]},{"cell_type":"markdown","source":["## 結果呈現\n","觀察模型是否有正確框出BBox"],"metadata":{"id":"CvO-ZfQTi8Ma"},"id":"CvO-ZfQTi8Ma"},{"cell_type":"code","source":["#指定照片的檔案路徑及檔名\n","\n","#IMG_FILE = 'VD03/valid/images/DSC_8733.jpg'\n","\n","IMG_FILE = 'VD03/valid/images/DSC_8812.jpg'"],"metadata":{"id":"KcHNs-JZRfnj"},"id":"KcHNs-JZRfnj","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["讀取影像檔案"],"metadata":{"id":"ov28LcqmLqQc"},"id":"ov28LcqmLqQc"},{"cell_type":"code","source":["import PIL\n","import sys\n","import numpy as np\n","from IPython.display import Image\n","\n","\n","#讀入照片，轉為numpy array格式。\n","image = PIL.Image.open(IMG_FILE)\n","image = np.asarray(image)\n","image.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PUTV9mc5jEMx","executionInfo":{"status":"ok","timestamp":1683275843576,"user_tz":-480,"elapsed":2,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"db85fec7-fdda-47de-91fd-5adf4335dca0"},"id":"PUTV9mc5jEMx","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1280, 1920, 3)"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["送進YOLOv7模型，並顯示結果"],"metadata":{"id":"7OVzyelXLvFU"},"id":"7OVzyelXLvFU"},{"cell_type":"code","source":["results = model([image])\n","\n","PIL.Image.fromarray(results.render()[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":754,"output_embedded_package_id":"1PO1Zu9qQOsxTwAiClq3t_1AYK_f4-idG"},"id":"7q9-p3X8jP-7","executionInfo":{"status":"ok","timestamp":1683275849639,"user_tz":-480,"elapsed":4269,"user":{"displayName":"tc Lin","userId":"05338448855796845949"}},"outputId":"8a5eddad-6a6e-4e6e-de19-2fb492888052"},"id":"7q9-p3X8jP-7","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"kEBvw_-bjrGc"},"id":"kEBvw_-bjrGc","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 參考資料\n","\n","- YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors (paper: https://arxiv.org/abs/2207.02696 )\n","- Official YOLOv7 github: https://github.com/WongKinYiu/yolov7\n","- 最新的物件偵測王者 YOLOv7 介紹 - TA家銘 ([https://medium.com/ai-academy-taiwan/206c6adf2e69](https://medium.com/ai-academy-taiwan/206c6adf2e69))\n","- 理解 YOLOv7 預測方式並且部署YOLOv7 模型成為一個服務 ([https://blog.infuseai.io/yolov7-model-deployment-in-primehub-deployment-99b377227447](https://blog.infuseai.io/yolov7-model-deployment-in-primehub-deployment-99b377227447))\n","- [Object Detection_YOLO] YOLOv7 論文筆記 ([https://hackmd.io/@YungHuiHsu/BJ7fpQyps?utm_source=preview-mode&utm_medium=rec](https://hackmd.io/@YungHuiHsu/BJ7fpQyps?utm_source=preview-mode&utm_medium=rec))\n"],"metadata":{"id":"93GzjBoo0VY1"},"id":"93GzjBoo0VY1"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}